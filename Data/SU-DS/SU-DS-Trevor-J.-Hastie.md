---
bio-current:
  name-cn: 
  name-en: Trevor J. Hastie
  email: 
    - hastie.web.stanford.edu
    - hastie@stanford.edu
  sex: male
  birth-date: 1953
  university: Stanford University 
  school: School of humanities & science [https://humsci.stanford.edu/]
  major: Statistics
  title-raw: Professor
  title: Professor
  interests: 
    - nonparametric regression
    - statistical computing
    - data mining
  homepage: 
    - https://statistics.stanford.edu/people/trevor-j-hastie
    - https://profiles.stanford.edu/trevor-hastie
    - https://web.stanford.edu/~hastie/
  github: 
  googlescholar:  
  aminer: https://www.aminer.cn/profile/trevor-hastie/53f48c61dabfaea7cd1ce7ad
  status: 在职
  last-update: # yyyy-mm-dd 最近一次信息更新日期
edu-phd:  # 读博经历
  university: Stanford University
  school: Statistics
  email: 
  date-start: 
  date-end: 1984
  advisor: # 格式：导师名 [邮箱/网址]
  degree: phd
edu-master: # 硕士经历，没有或找不到，可不填
  university: University of Cape Town
  school: Statistics
  date-start: 
  date-end: 1979
  advisor:
edu-bachelor:  # 本科经历，没有或找不到，可不填
  university: Rhodes University
  school: Statistics
  major: 
  date-start: 
  date-end: 1976 
page-other:   # 其他有用的链接，部分可从学者主页子栏目获得
  publication: https://web.stanford.edu/~hastie/pub.htm
  research: https://web.stanford.edu/~hastie/research.htm
  software: https://web.stanford.edu/~hastie/swData.htm
  project: 
  blog: 
  arxiv: 
  linkedin: https://web.stanford.edu/~hastie/links.htm
  weibo:
  twitter:
  wikipedia:
  baidu-baike:
collaboration: # 合作研究，关注学者和其他哪些学科的人合作，具体研究哪些主题
  - 
    with: # 合作者
    project: # 研究主题
  - 
    with: 
    project: 
group: # 所属团队，学者可能有不同的兴趣小组，可以列上去
job-faculty-1: # 所属机构，若有多个增加编号即可，字段填写参看示例文件
  university: 
  school: 
  major: 
  email: 
  homepage: # 机构内学者主页
  date-start: 
  title: 
  type: 
job-post-doc: # 博士后研究员，字段填写参看示例文件，若无可不填写
  university: 
  school: 
  email: 
  date-start: 
  date-end: 
  advisor: 
---

# Profile

![Trevor J. Hastie](https://statistics.stanford.edu/sites/g/files/sbiybj6031/f/styles/large-square/public/hastie_new.jpg?itok=_rxkY4Xt)

# Biography[English]

Trevor Hastie was born in South Africa in 1953. He received his university education from Rhodes University, South Africa (BS), University of Cape Town (MS), and Stanford University (Ph.D Statistics 1984).

His first employment was with the South African Medical Research Council in 1977, during which time he earned his MS from UCT. In 1979 he spent a year interning at the London School of Hygiene and Tropical Medicine, the Johnson Space Center in Houston Texas, and the Biomath department at Oxford University. He joined the Ph.D program at Stanford University in 1980. After graduating from Stanford in 1984, he returned to South Africa for a year with his earlier employer SA Medical Research Council. He returned to the USA in March 1986 and joined the statistics and data analysis research group at what was then AT&T Bell Laboratories in Murray Hill, New Jersey. After eight years at Bell Labs, he returned to Stanford University in 1994 as Professor in Statistics and Biostatistics. In 2013 he was named the John A. Overdeck Professor of Mathematical Sciences, and in 2018 was elected to the National Academy of Sciences.

His main research contributions have been in applied statistics; he has published over 200 articles and written five books in this area: "Generalized Additive Models" (with R. Tibshirani, Chapman and Hall, 1991), "Elements of Statistical Learning" (with R. Tibshirani and J. Friedman, Springer 2001; second edition 2009), "An Introduction to Statistical Learning, with Applications in R" (with G. James, D. Witten and R. Tibshirani, Springer 2013) and "Statistical Learning with Sparsity" (with R. Tibshirani and M. Wainwright, Chapman and Hall, 2015) and "Computer Age Statistical Inference" (with Bradley Efron, Cambridge 2016). He has also made contributions in statistical computing, co-editing (with J. Chambers) a large software library on modeling tools in the S language ("Statistical Models in S", Wadsworth, 1992), which form the foundation for much of the statistical modeling in R. His current research focuses on applied statistical modeling and prediction problems in biology and genomics, medicine and industry.

# Biography[中文]

# Interests[English]

- nonparametric regression
- statistical computing
- data mining

# Interests[中文]

# Education[English]

- PhD in Statistics, 1984
    
    Stanford University

- M.S. in Statistics, 1979
    
    University of Cape Town

- B. Math. in Statistics and Computer Science, 1976
    
    Rhodes University

# Education[中文]

# Awards[English]

- AMiner Most Influential Scholar Award in Machine Learning,2016
- AMiner Most Influential Scholar Award in Data Mining,2016

# Awards[中文]

# Talks[English]

# Talks[中文]

# Work experience[English]

# Work experience[中文]

# Publication[English]

- Zijun Gao and \***Trevor Hastie**\*. LinCDE: Conditional density estimation via Lindsey's method.(https://arxiv.org/abs/2107.12713) Lindsey's method allows for smooth density estimation by turning the density problem into a Poisson GLM. In particular, we represent an exponential tilt function in a basis of natural splines, and use discretization to deal with the normalization. In this paper we extend the method to conditional density estimation via trees and then gradient boosting with trees.
- Yosuke Tanigawa, Junyang Qian, Guhan Venkataraman, Johanne Justesen, Ruilin Li, Robert Tibshirani\*,**Trevor Hastie**\*, Manuel Rivas. Significant Sparse Polygenic Risk Scores across 428 traits in UK Biobank.(https://www.medrxiv.org/content/10.1101/2021.09.02.21262942v1) In this survey across the more than 1,600 traits in the UK Biobank, we report 428 strongly significant (p<2.5e-5) sparse polygenic risk models, computed by the snpnet lasso model developed by this team.
- Swarnadip Ghosh\*,**Trevor Hastie**\* and Art Owen. Scalable logistic regression with crossed random effects.(https://arxiv.org/abs/2105.13747) We develop an approach for fitting crossed random-effect logisitic regression models at massive scales, with applications in ecommerce. We adapt a procedure of Schall (1991) and backfitting algorithms to achieve O(n) algorithms.
- Zijun Gao and \***Trevor Hastie**\*. DINA: Estimating Heterogenous Treatment Effects in Exponential Family and Cox Models.(https://arxiv.org/abs/2103.04277) We extend the R-learner framework to exponential families and the Cox model. Here we define the treatment effect to be the difference in natural parameter or DINA.
- Stephen Bates\*,**Trevor Hastie**\* and Rob Tibshirani. Cross-validation: what does it estimate and how well does it do it?(https://arxiv.org/abs/2104.00673) Although CV is ubiquitous in data science, some of its properties are poorly understood. In this paper we argue that CV is better at estimating expected prediction error rather than the prediction error for the particular model fit to the training set. We also provide a method for computing the standard error of the CV estimate, which is bigger than the commonly used naive estimate which ignores the correlations in the folds.
- Elena Tuzhilina, Leonardo Tozzi and Trevor Hastie. Canonical Correlation Analysis in high dimensions with structured regularization.(https://arxiv.org/abs/2011.01650)We develop structurally regularized versions of CCA for very high-dimensional MRI images from neuroscience experiments. To appear, Statistical Modelling, 2021.
- J. Kenneth Tay, Balasubramanian Narasimhan and Trevor Hastie. Elastic Net Regularization Paths for All Generalized Linear Models.(http://arxiv.org/abs/2103.03475) This paper describes some of the substantial enhancements to the glmnet R package ver 4.1+. All programmed GLM families are accommodated through a family() argument. We also discuss relaxed fits, and facilities for modeling stop/start data and strata in survival models.

# Publication[中文]

# Information Reference

- homepage: https://statistics.stanford.edu/people/trevor-j-hastie
- homepage: https://profiles.stanford.edu/trevor-hastie
- homepage: https://web.stanford.edu/~hastie/ 
- aminer: https://www.aminer.cn/profile/trevor-hastie/53f48c61dabfaea7cd1ce7ad

# Notes