---
bio-current:
  name-cn: 
  name_en: Peter Bartlett
  email: 
    - 
    
              bartlett@stat.berkeley.edu
              peter@berkeley.edu
           # 如果有多个邮箱，请都填写上
  sex: male # male/female
  birth-date: # yyyy 到年即可
  university: University of California��Berkeley 
  school: Dept, of Statistics [https://statistics.berkeley.edu/people/faculty] # 格式：学院名称[学院官网链接]
  major: 
  title-raw: Professor# 主页原始字符串
  title: Professor # Associate Professor/Assistant Professor/Professor
  interests: 
    - machine learning
    - statistical learning theory
    - adaptive control
  # 分点罗列，依次以 ‘-’ 开头
  homepage: 
    - https://statistics.berkeley.edu/people/peter-bartlett
    - https://www.stat.berkeley.edu/~bartlett/ 
    - https://people.eecs.berkeley.edu/~bartlett/
    # 如果有多个主页，请都填写上
  github: 
  googlescholar: https://scholar.google.com/citations?user=yQNhFGUAAAAJ
  aminer: https://www.aminer.cn/profile/peter-l-bartlett/53f46be1dabfaeecd6a225b5 # 从这里查找 https://www.aminer.org/search/person
  status: 在职 # 选项如下：在读/在职/离职/退休/亡故
  last-update: # yyyy-mm-dd 最近一次信息更新日期
edu-phd:  # 读博经历
  university: 
  school: 
  email: 
  date-start: 
  date-end: 
  advisor: # 格式：导师名 [邮箱/网址]
  degree: # phd
edu-master: # 硕士经历，没有或找不到，可不填
  university: 
  school: 
  date-start: 
  date-end: 
  advisor:
edu-bachelor:  # 本科经历，没有或找不到，可不填
  university: 
  school: 
  major: 
  date-start: 
  date-end: 
page-other:   # 其他有用的链接，部分可从学者主页子栏目获得
  publication: https://www.stat.berkeley.edu/~bartlett/publications/recent-pubs.html
  research: https://vcresearch.berkeley.edu/faculty/peter-bartlett
  software: 
  project: 
  blog: 
  arxiv: 
  linkedin: https://www.linkedin.com/in/peter-bartlett-a3b0169/?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAGaj08BjjDMpp6rzHLA00JUoooLx-SJtsE
  weibo:
  twitter:
  wikipedia:
  baidu-baike:
collaboration: # 合作研究，关注学者和其他哪些学科的人合作，具体研究哪些主题
  - 
    with: # 合作者
    project: # 研究主题
  - 
    with: 
    project: 
group: # 所属团队，学者可能有不同的兴趣小组，可以列上去
job-faculty-1: # 所属机构，若有多个增加编号即可，字段填写参看示例文件
  university: 
  school: 
  major: 
  email: 
  homepage: # 机构内学者主页
  date-start: 
  title: 
  type: 
job-post-doc: # 博士后研究员，字段填写参看示例文件，若无可不填写
  university: 
  school: 
  email: 
  date-start: 
  date-end: 
  advisor: 
---

# Profile

![Peter Bartlett](https://statistics.berkeley.edu/sites/default/files/styles/crop_person/public/faculty/Peter-Bartlett2.jpg?h=cdfd68d0&itok=hp_wnsMa)

# Biography[English]

Peter Bartlett is a professor in the Department of Electrical Engineering and Computer Sciences and the Department of Statistics at the University of California at Berkeley, Associate Director of the Simons Institute for the Theory of Computing, Director of the Foundations of Data Science Institute, and Director of the Collaboration on the Theoretical Foundations of Deep Learning. His research interests include machine learning and statistical learning theory. He is the co-author, with Martin Anthony, of the book Neural Network Learning: Theoretical Foundations. He has served as an associate editor of the journals Bernoulli, Mathematics of Operations Research, the Journal of Artificial Intelligence Research, the Journal of Machine Learning Research, the IEEE Transactions on Information Theory, Machine Learning, and Mathematics of Control Signals and Systems, and as program committee co-chair for COLT and NIPS. He has consulted to a number of organizations, including General Electric, Telstra, SAC Capital Advisors, and Sentient. He has been a Professor in Mathematical Sciences at the Queensland University of Technology (2011-2017), a Miller Institute Visiting Research Professor in Statistics and Computer Science at U.C. Berkeley (Fall 2001), a fellow, senior fellow, and professor in the Research School of Information Sciences and Engineering at the Australian National University's Institute for Advanced Studies (1993-2003), an honorary professor at the University of Queensland and a visiting professor at the University of Paris. He was awarded the Malcolm McIntosh Prize for Physical Scientist of the Year in Australia in 2001, and was chosen as an Institute of Mathematical Statistics Medallion Lecturer in 2008, an IMS Fellow and Australian Laureate Fellow in 2011, and a Fellow of the ACM in 2018. He was elected to the Australian Academy of Science in 2015.

# Biography[中文]

# Interests[English]

My research interests are in the areas of machine learning, statistical learning theory, and reinforcement learning. I work on the theoreticalanalysis of computationally efficient methods for large or otherwise complex prediction problems. One example is structured prediction problems, where there is considerable complexity to the space of possible predictions. Such methods are important in a variety of application areas, including natural language processing, computer vision, and bioinformatics. A second area of interest is the analysis of prediction methods in a deterministic, game-theoretic setting. As well as being of interest in areas such as computer security, where an adversarial environment is a reasonable model, this analysis also provides insight into the design and understanding of prediction methods in a probabilistic setting. A third area of interest is the design of methods for large scale sequential decision problems, such as control of Markov decision processes. Again, computational efficiency is a crucial requirement. This is a common feature in all of these areas: the interplay between the constraint of computational efficiency and the statistical properties of a method.

# Interests[中文]

# Education[English]

# Education[中文]

# Awards[English]

# Awards[中文]

# Talks[English]

Benign Overfitting in Linear Regression
AI Institute "Geometry of Deep Learning", Microsoft Research Redmond, August 26-28, 2019. [slides]
Frontiers of Deep Learning Workshop, Simons Institute for the Theory of Computing, UC Berkeley, July 15-18, 2019. [slides]
Google, Mountain View, June 17, 2019. [slides]
Peter G. Hall Conference 2019: Statistics and Machine Learning, Department of Statistics, UC Davis, May 10-11, 2019. [slides]
Tutorial: Generalization in Deep Learning
Deep Learning Boot Camp, Simons Institute for the Theory of Computing, May 28-31, 2019. With Sasha Rakhlin. [slides]
Optimizing Probability Distributions for Learning: Sampling meets Optimization
University of California at Los Angeles Mathematics Colloquium May 2, 2019. [slides]
University of Southern California MASCLE Machine Learning Seminar April 16, 2019. [slides]
BAIR/BDD Workshop. March 25, 2019. [slides]
University of Pennsylvania PRiML Seminar February 24, 2019. [slides]
Generalization and Optimization in Deep Networks
YES X : "Understanding Deep Learning: Generalization, Approximation and Optimization", Eurandom March 19-22, 2019. [slides: 1, 2, 3]
Accurate Prediction from Interpolation: A New Challenge for Statistical Learning Theory
NAS Colloquium: The Science of Deep Learning March 13-14, 2019. [slides]
Efficient Optimal Strategies for Prediction Games
University of Queensland Statistics, Modelling and Operations Research Seminar October 4, 2018. [slides]
Representation, Optimization and Generalization in Deep Learning
BayLearn2018 Bay Area Machine Learning Symposium, Facebook, October 11, 2018. [slides]
DIMACS/TRIPODS Workshop on Optimization in Machine Learning, Lehigh University, August 13-15, 2018. [slides]
Future Challenges in Statistical Scalability, Isaac Newton Institute for Mathematical Sciences, June 27, 2018. [slides]
Foundations of Machine Learning Reunion Workshop, Simons Institute for the Theory of Computing, June 7, 2018. [slides]
Bridging Mathematical Optimization, Information Theory, and Data Science, Princeton Center for Statistics and Machine Learning, May 14, 2018. [slides]
Modern Challenges of Learning Theory, Centre de Recherches Mathematiques, April 23, 2018. [slides]
University of Queensland Maths Colloquium January 25, 2018. [slides]
IEOR Department Colloquium. October 9, 2017. [slides]
Statistical properties of deep networks
JSM session on Theory at the Intersection of Machine Learning and Statistics August 2, 2018. [slides]
NIPS Workshop on Deep Learning Theory and Practice. December 9, 2017. [slides]
BAIR/BDD Workshop. November 28, 2017. [slides]
Machine Learning at Berkeley. October 5, 2017. [slides]
The optimal strategy for a linear regression game [slides]
Dagstuhl seminar. June 19-23, 2017.
Topics in prediction and learning [Lecture 1, Lectures 2 and 3, Lecture 4, references]
ENSAE/CREST. Feb 27-Mar 9, 2017.
Efficient Optimal Strategies for Universal Prediction. [Slides: pdf]
Stochastics and Statistics Seminar, MIT. December 11, 2015.
Prediction and sequential decision problems in adversarial environments. [Slides: pdf]
CDAR Symposium. Berkeley. October 16, 2015.
Efficient minimax strategies for online prediction. [Slides: pdf]
ITA. February 6, 2015.
Caltech. February 9, 2015.
Learning in Markov decision problems. [Slides: pdf]
[Linear bandits survey slides: pdf]
UCLA. November 10, 2014.
Model selection and computational oracle inequalities for large scale problems. [Slides: pdf]
Workshop on Algorithms for Modern Massive Data Sets Stanford University. July 10 - 13, 2012.
Large scale model selection and computational oracle inequalities [Slides: pdf]
Conference on Statistical Learning and Data Mining Rackham Graduate School, University of Michigan, Ann Arbor, MI, June 5 - 7, 2012.
Online Prediction [Slides: pdf]
[Lecture notes: pdf]
Learning Theory: State of the Art Institut Henri Poincare, Paris, May 9-11, 2011.
Optimal online prediction in adversarial environments [Slides: pdf]
The Second Asian Conference on Machine Learning Tokyo Institute of Technology, Tokyo, Japan, November 8-10, 2010.
An online allocation problem: Dark pools [Slides: pdf]
The Mathematics of Ranking American Institute of Mathematics, Palo Alto, California, August 16-20, 2010.
l1-regularized linear regression: persistence and oracle inequalities [Slides: pdf]
Probability and Statistics - an international conference in honor of P.L. Hsu's 100th birthday Peking University, Beijing, China. July 6, 2010.
10th International Vilnius Conference on Probability Theory and Mathematical Statistics. June 30, 2010.
Convex methods for classification [Slides: pdf]
IMS Medallion Lecture. June 2008.
Optimism in Sequential Decision Making [Slides: pdf]
UC Berkeley Statistics. September 2007.
Consistency of AdaBoost [Slides: pdf]
Google. May 2007.
AdaBoost and other Large Margin Classifiers: Convexity in Classification [Slides: pdf]
Presented at DASP 2006. December 2006.
Convex methods for classification [Slides: pdf]
AdaBoost and other Large Margin Classifiers: Convexity in Classification [Slides: ps]
Presented at the Institute of Statistical Science, Academia Sinica, Taipei, Taiwan., July 31, 2006.
AdaBoost is Universally Consistent [Slides: ps, pdf]
Presented at the 2006 Summer Institute held by the Institute of Information Science (IIS), Academia Sinica, Taipei, Taiwan., August 3, 2006.
Regression Methods for Pattern Classification: Statistical Properties of Large Margin Classifiers [Slides: ps, pdf]
Presented at Mathematisches Forschungsinstitut Oberwolfach, October 16-22, 2005.
Empirical Minimization and Risk Bounds [Slides: ps]
Statistical Properties of Large Margin Classifiers [Slides: ps, pdf]
Large Margin Classifiers: Convexity and Classification [Slides: ps, pdf]
Large Margin Methods for Structured Classification: Exponentiated Gradient Algorithms [Slides: ps, ps.gz]
Local Rademacher Averages and Empirical Minimization [Slides: ps, pdf]
The Role of Convexity in Prediction Problems. [Slides: ps, ps.gz; Handouts: ps, ps.gz]
Presented at UC Berkeley EECS Joint Colloquium Distinguished Lecture Series, September 17, 2003.
Prediction Algorithms: Complexity, Concentration, and Convexity. [Slides: ps, ps.gz; Handouts: ps, ps.gz]
Presented at SYSID2003: 13th IFAC Symposium on System Identification, Rotterdam, The Netherlands, 27-29 August, 2003.
See: Extended abstract.
Convexity, Classification, and Risk Bounds. [Slides: ps, ps.gz; Handouts: ps, ps.gz]
Presented at Workshop on Advances in Machine Learning, Montreal, Canada, June 8-11, 2003, and AMS/IMS/SIAM Joint Summer Research Conference on Machine Learning, Statistics, and Discovery, Snowbird, Utah, June 22-26, 2003.
See: Convexity, classification, and risk bounds. Peter L. Bartlett, Michael I. Jordan and Jon D. McAuliffe. Technical Report 638, Department of Statistics, U.C. Berkeley, 2003.
NIPS'98 Tutorial (an introduction to learning theory)

# Talks[中文]

# Work experience[English]

# Work experience[中文]

# Publication[English]

[1]	P. L. Bartlett. Lower bounds on the Vapnik-Chervonenkis dimension of multi-layer threshold networks. In Proceedings of the Sixth Annual ACM Conference on Computational Learning Theory, pages 144--150. ACM Press, 1993. [ bib ]
[2]	P. L. Bartlett. The sample size necessary for learning in multi-layer networks. In Proceedings of the Fourth Australian Conference on Neural Networks, pages 14--17, 1993. [ bib ]
[3]	D. R. Lovell and P. L. Bartlett. Error and variance bounds in multi-layer neural networks. In Proceedings of the Fourth Australian Conference on Neural Networks, pages 161--164, 1993. [ bib ]
[4]	P. L. Bartlett. Vapnik-Chervonenkis dimension bounds for two- and three-layer networks. Neural Computation, 5(3):371--373, 1993. [ bib ]
[5]	W. S. Lee, P. L. Bartlett, and R. C. Williamson. The Vapnik-Chervonenkis dimension of neural networks with restricted parameter ranges. In Proceedings of the Fifth Australian Conference on Neural Networks, pages 198--201, 1994. [ bib ]
[6]	P. L. Bartlett. Learning quantized real-valued functions. In Proceedings of Computing: the Australian Theory Seminar, pages 24--35. University of Technology Sydney, 1994. [ bib ]
[7]	W. S. Lee, P. L. Bartlett, and R. C. Williamson. Lower bounds on the VC-dimension of smoothly parametrized function classes. In Proceedings of the Seventh Annual ACM Conference on Computational Learning Theory, pages 362--367. ACM Press, 1994. [ bib ]
[8]	P. L Bartlett and R. C. Williamson. Sample complexity versus approximation error. Technical report, 1994. [ bib ]
[9]	P. L. Bartlett, P. M. Long, and R. C. Williamson. Fat-shattering and the learnability of real-valued functions. In Proceedings of the Seventh Annual ACM Conference on Computational Learning Theory, pages 299--310. ACM Press, 1994. [ bib ]
[10]	P. L. Bartlett, P. Fischer, and K.-U. Höffgen. Exploiting random walks for learning. In Proceedings of the Seventh Annual ACM Conference on Computational Learning Theory, pages 318--327. ACM Press, 1994. [ bib ]
[11]	P. L. Bartlett. Computational learning theory. In A. Kent and J. G. Williams, editors, Encyclopedia of Computer Science and Technology, volume 31, pages 83--99. Marcel Dekker, 1994. [ bib ]
[12]	W. S. Lee, P. L. Bartlett, and R. C. Williamson. Efficient agnostic learning of neural networks with bounded fan-in. In Proceedings of the Sixth Australian Conference on Neural Networks, pages 201--204, 1995. [ bib ]
[13]	P. L. Bartlett and R. C. Williamson. The sample complexity of neural network learning with discrete inputs. In Proceedings of the Sixth Australian Conference on Neural Networks, pages 189--192, 1995. [ bib ]
[14]	M. Anthony and P. L. Bartlett. Function learning from interpolation. In Computational Learning Theory: Second European Conference, EUROCOLT 95, Barcelona Spain, March 1995, Proceedings, pages 211--221, 1995. [ bib ]
[15]	W. S. Lee, P. L. Bartlett, and R. C. Williamson. On efficient agnostic learning of linear combinations of basis functions. In Proceedings of the Eighth Annual ACM Conference on Computational Learning Theory, pages 369--376. ACM Press, 1995. [ bib ]
[16]	P. L. Bartlett and P. M. Long. More theorems about scale sensitive dimensions and learning. In Proceedings of the Eighth Annual ACM Conference on Computational Learning Theory, pages 392--401. ACM Press, 1995. [ bib ]
[17]	P. L. Bartlett and S. Dasgupta. Exponential convergence of a gradient descent algorithm for a class of recurrent neural networks. In Proceedings of the 38th Midwest Symposium on Circuits and Systems, 1995. [ bib ]
[18]	W. S. Lee, P. L. Bartlett, and R. C. Williamson. Lower bounds on the VC-dimension of smoothly parametrized function classes. Neural Computation, 7:990--1002, 1995. (See also correction, Neural Computation, 9: 765--769, 1997). [ bib ]
[19]	L. C. Kammer, R. R. Bitmead, and P. L. Bartlett. Adaptive tracking identification: the art of defalsification. In Proceedings of the 1996 IFAC World Congress, 1996. [ bib ]
[20]	W. S. Lee, P. L. Bartlett, and R. C. Williamson. The importance of convexity in learning with squared loss. In Proceedings of the Ninth Annual Conference on Computational Learning Theory, pages 140--146. ACM Press, 1996. [ bib ]
[21]	J. Shawe-Taylor, P. L. Bartlett, R. C. Williamson, and M. Anthony. A framework for structural risk minimization. In Proceedings of the Ninth Annual Conference on Computational Learning Theory, pages 68--76. ACM Press, 1996. [ bib ]
[22]	P. L. Bartlett, S. Ben-David, and S. R. Kulkarni. Learning changing concepts by exploiting the structure of change. In Proceedings of the Ninth Annual Conference on Computational Learning Theory, pages 131--139. ACM Press, 1996. [ bib ]
[23]	L. Kammer, R. R. Bitmead, and P. L. Bartlett. Signal-based testing of LQ-optimality of controllers. In Proceedings of the 35th IEEE Conference on Decision and Control, pages FA17--2, 3620--3623. IEEE, 1996. [ bib ]
[24]	P. L. Bartlett and S. R. Kulkarni. The complexity of model classes, and smoothing noisy data (invited). In Proceedings of the 35th IEEE Conference on Decision and Control, pages TM09--4, 2312--2317. IEEE, 1996. [ bib ]
[25]	A. Kowalczyk, J. Szymanski, P. L. Bartlett, and R. C. Williamson. Examples of learning curves from a modified VC-formalism. In Advances in Neural Information Processing Systems 8, pages 344--350, 1996. [ bib ]
[26]	P. L. Bartlett and R. C. Williamson. The Vapnik-Chervonenkis dimension and pseudodimension of two-layer neural networks with discrete inputs. Neural Computation, 8:653--656, 1996. [ bib ]
[27]	P. L. Bartlett, P. M. Long, and R. C. Williamson. Fat-shattering and the learnability of real-valued functions. Journal of Computer and System Sciences, 52(3):434--452, 1996. (special issue on COLT`94). [ bib ]
[28]	M. Anthony, P. L. Bartlett, Y. Ishai, and J. Shawe-Taylor. Valid generalisation from approximate interpolation. Combinatorics, Probability, and Computing, 5:191--214, 1996. [ bib ]
[29]	P. L. Bartlett and D. P. Helmbold. Learning changing problems. Technical report, 1996. [ bib ]
[30]	W. S. Lee, P. L. Bartlett, and R. C. Williamson. Efficient agnostic learning of neural networks with bounded fan-in. IEEE Transactions on Information Theory, 42(6):2118--2132, 1996. [ bib ]
[31]	Peter L. Bartlett, Anthony Burkitt, and Robert C. Williamson, editors. Proceedings of the Seventh Australian Conference on Neural Networks. Australian National University, 1996. [ bib ]
[32]	G. Loy and P. L. Bartlett. Generalization and the size of the weights: an experimental study. In Proceedings of the Eighth Australian Conference on Neural Networks, pages 60--64, 1997. [ bib ]
[33]	P. L. Bartlett. Neural network learning. (abstract of invited talk.). In CONTROL 97 Conference Proceedings, Institution of Engineers Australia, page 543, 1997. [ bib ]
[34]	J. Baxter and P. L. Bartlett. A result relating convex n-widths to covering numbers with some applications to neural networks. In S. Ben-David, editor, Proceedings of the Third European Conference on Computational Learning Theory (EuroCOLT'97), pages 251--259. Springer, 1997. [ bib ]
[35]	P. L. Bartlett, T. Linder, and G. Lugosi. A minimax lower bound for empirical quantizer design. In S. Ben-David, editor, Proceedings of the Third European Conference on Computational Learning Theory (EuroCOLT'97), pages 220--222. Springer, 1997. [ bib ]
[36]	P. L. Bartlett, T. Linder, and G. Lugosi. The minimax distortion redundancy in empirical quantizer design (abstract). In Proceedings of the 1997 IEEE International Symposium on Information Theory, page 511, 1997. [ bib ]
[37]	R. E. Schapire, Y. Freund, P. L. Bartlett, and W. S. Lee. Boosting the margin: A new explanation for the effectiveness of voting methods. In Machine Learning: Proceedings of the Fourteenth International Conference, pages 322--330, 1997. [ bib ]
[38]	P. L. Bartlett. For valid generalization, the size of the weights is more important than the size of the network. In Advances in Neural Information Processing Systems 9, pages 134--140, 1997. [ bib ]
[39]	W. S. Lee, P. L. Bartlett, and R. C. Williamson. Correction to `lower bounds on the VC-dimension of smoothly parametrized function classes'. Neural Computation, 9:765--769, 1997. [ bib ]
[40]	P. L. Bartlett. Book review: `Neural networks for pattern recognition,' Christopher M. Bishop. Statistics in Medicine, 16(20):2385--2386, 1997. [ bib ]
[41]	P. L. Bartlett, S. R. Kulkarni, and S. E. Posner. Covering numbers for real-valued function classes. IEEE Transactions on Information Theory, 43(5):1721--1724, 1997. [ bib ]
[42]	L. Mason, P. L. Bartlett, and M. Golea. Generalization in threshold networks, combined decision trees and combined mask perceptrons. In T. Downs, M. Frean, and M. Gallagher, editors, Proceedings of the Ninth Australian Conference on Neural Networks (ACNN'98), pages 84--88. University of Queensland, 1998. [ bib ]
[43]	B. Schölkopf, P. L. Bartlett, A. Smola, and R. Williamson. Support vector regression with automatic accuracy control. In L. Niklasson, M. Boden, and T. Ziemke, editors, Perspectives in Neural Computing: Proceedings of the 8th International Conference on Artificial Neural Networks (ICANN'98), pages 111--116. Springer-Verlag, 1998. [ bib ]
[44]	L. C. Kammer, R. R. Bitmead, and P. L. Bartlett. Direct iterative tuning via spectral analysis. In Proceedings of the IEEE Conference on Decision and Control, volume 3, pages 2874--2879, 1998. [ bib ]
[45]	M. Golea, P. L. Bartlett, and W. S. Lee. Generalization in decision trees and DNF: Does size matter? In Advances in Neural Information Processing Systems 10, pages 259--265, 1998. [ bib ]
[46]	J. Baxter and P. L. Bartlett. The canonical distortion measure in feature space and 1-NN classification. In Advances in Neural Information Processing Systems 10, pages 245--251, 1998. [ bib ]
[47]	P. L. Bartlett. The sample complexity of pattern classification with neural networks: the size of the weights is more important than the size of the network. IEEE Transactions on Information Theory, 44(2):525--536, 1998. [ bib ]
[48]	P. L. Bartlett and P. M. Long. Prediction, learning, uniform convergence, and scale-sensitive dimensions. Journal of Computer and System Sciences, 56(2):174--190, 1998. (special issue on COLT`95). [ bib ]
[49]	L. C. Kammer, R. R. Bitmead, and P. L. Bartlett. Optimal controller properties from closed-loop experiments. Automatica, 34(1):83--91, 1998. [ bib ]
[50]	P. L. Bartlett and M. Vidyasagar. Introduction to the special issue on learning theory. Systems and Control Letters, 34:113--114, 1998. [ bib ]
[51]	P. L. Bartlett and S. Kulkarni. The complexity of model classes, and smoothing noisy data. Systems and Control Letters, 34(3):133--140, 1998. [ bib ]
[52]	P. L. Bartlett, T. Linder, and G. Lugosi. The minimax distortion redundancy in empirical quantizer design. IEEE Transactions on Information Theory, 44(5):1802--1813, 1998. [ bib ]
[53]	J. Shawe-Taylor, P. L. Bartlett, R. C. Williamson, and M. Anthony. Structural risk minimization over data-dependent hierarchies. IEEE Transactions on Information Theory, 44(5):1926--1940, 1998. [ bib ]
[54]	W. S. Lee, P. L. Bartlett, and R. C. Williamson. The importance of convexity in learning with squared loss. IEEE Transactions on Information Theory, 44(5):1974--1980, 1998. [ bib ]
[55]	P. L. Bartlett, V. Maiorov, and R. Meir. Almost linear VC dimension bounds for piecewise polynomial networks. Neural Computation, 10(8):2159--2173, 1998. [ bib ]
[56]	R. E. Schapire, Y. Freund, P. L. Bartlett, and W. S. Lee. Boosting the margin: a new explanation for the effectiveness of voting methods. Annals of Statistics, 26(5):1651--1686, 1998. [ bib ]
[57]	Peter L. Bartlett and Yishay Mansour, editors. Proceedings of the Eleventh Annual Conference on Computational Learning Theory. ACM Press, 1998. [ bib ]
[58]	P. L. Bartlett and J. Baxter. Voting methods for data segmentation. In Proceedings of the Advanced Investment Technology Conference, pages 35--40. Bond University, 1999. [ bib ]
[59]	L. Mason, P. L. Bartlett, and J. Baxter. Error bounds for voting classifiers using margin cost functions (invited abstract). In Proceedings of the IEEE Information Theory Workshop on Detection, Estimation, Classification and Imaging, page 36, 1999. [ bib ]
[60]	P. L. Bartlett and S. Ben-David. Hardness results for neural network approximation problems. In Proceedings of the Fourth European Conference on Computational Learning Theory, pages 50--62, 1999. [ bib ]
[61]	Y. Guo, P. L. Bartlett, J. Shawe-Taylor, and R. C. Williamson. Covering numbers for support vector machines. In Proceedings of the Twelfth Annual Conference on Computational Learning Theory, pages 267--277, 1999. [ bib ]
[62]	T. Koshizen, P. L. Bartlett, and A. Zelinsky. Sensor fusion of odometry and sonar sensors by the Gaussian mixture Bayes' technique in mobile robot position estimation. In Proceedings of the 1999 IEEE International Conference on Systems, Man and Cybernetics, volume 4, pages 742--747, 1999. [ bib ]
[63]	B. Schölkopf, P. L. Bartlett, A. Smola, and R. Williamson. Shrinking the tube: a new support vector regression algorithm. In Advances in Neural Information Processing Systems 11, pages 330--336, 1999. [ bib ]
[64]	L. Mason, P. L. Bartlett, and J. Baxter. Direct optimization of margins improves generalization in combined classifiers. In Advances in Neural Information Processing Systems 11, pages 288--294, 1999. [ bib ]
[65]	P. L. Bartlett, V. Maiorov, and R. Meir. Almost linear VC dimension bounds for piecewise polynomial networks. In Advances in Neural Information Processing Systems 11, pages 190--196, 1999. [ bib ]
[66]	P. L. Bartlett and J. Shawe-Taylor. Generalization performance of support vector machines and other pattern classifiers. In B. Schölkopf, C. J. C. Burges, and A. J. Smola, editors, Advances in Kernel Methods -- Support Vector Learning, pages 43--54. MIT Press, 1999. [ bib ]
[67]	P. L. Bartlett. Efficient neural network learning. In V. D. Blondel, E. D. Sontag, M. Vidyasagar, and J. C. Willems, editors, Open Problems in Mathematical Systems Theory and Control, pages 35--38. Springer Verlag, 1999. [ bib ]
[68]	P. L. Bartlett and G. Lugosi. An inequality for uniform deviations of sample averages from their means. Statistics and Probability Letters, 44(1):55--62, 1999. [ bib ]
[69]	Martin Anthony and Peter L. Bartlett. Neural Network Learning: Theoretical Foundations. Cambridge University Press, 1999. 404pp. ISBN 978-0-521-57353-X. Reprinted 2001, 2002. Paperback edition 2009; ISBN 978-0-521-11862-0. [ bib | .html ]
[70]	P. L. Bartlett and J. Baxter. Estimation and approximation bounds for gradient-based reinforcement learning. In Proceedings of the Thirteenth Annual Conference on Computational Learning Theory, pages 133--141, 2000. [ bib ]
[71]	P. L. Bartlett, S. Boucheron, and G. Lugosi. Model selection and error estimation. In Proceedings of the Thirteenth Annual Conference on Computational Learning Theory, pages 286--297, 2000. [ bib ]
[72]	J. Baxter and P. L. Bartlett. GPOMDP: An on-line algorithm for estimating performance gradients in POMDP's, with applications. In Proceedings of the 2000 International Conference on Machine Learning, pages 41--48, 2000. [ bib ]
[73]	L. Mason, J. Baxter, P. L. Bartlett, and M. Frean. Boosting algorithms as gradient descent. In Advances in Neural Information Processing Systems 12, pages 512--518, 2000. [ bib ]
[74]	J. Baxter and P. L. Bartlett. Direct gradient-based reinforcement learning (invited). In Proceedings of the International Symposium on Circuits and Systems, pages III--271--274, 2000. [ bib ]
[75]	P. L. Bartlett and J. Baxter. Stochastic optimization of controlled partially observable Markov decision processes. In Proceedings of the IEEE Conference on Decision and Control, volume 1, pages 124--129, 2000. [ bib ]
[76]	L. Mason, P. L. Bartlett, and J. Baxter. Improved generalization through explicit optimization of margins. Machine Learning, 38(3):243--255, 2000. [ bib ]
[77]	L. C. Kammer, R. R. Bitmead, and P. L. Bartlett. Direct iterative tuning via spectral analysis. Automatica, 36(9):1301--1307, 2000. [ bib ]
[78]	B. Schölkopf, A. Smola, R. C. Williamson, and P. L. Bartlett. New support vector algorithms. Neural Computation, 12(5):1207--1245, 2000. [ bib ]
[79]	S. Parameswaran, M. F. Parkinson, and P. L. Bartlett. Profiling in the ASP codesign environment. Journal of Systems Architecture, 46(14):1263--1274, 2000. [ bib ]
[80]	P. L. Bartlett, S. Ben-David, and S. R. Kulkarni. Learning changing concepts by exploiting the structure of change. Machine Learning, 41(2):153--174, 2000. [ bib ]
[81]	A. J. Smola, P. L. Bartlett, B. Schölkopf, and D. Schuurmans. Introduction to large margin classifiers. In Advances in Large Margin Classifiers, pages 1--29. MIT Press, 2000. [ bib ]
[82]	L. Mason, J. Baxter, P. L. Bartlett, and M. Frean. Functional gradient techniques for combining hypotheses. In A. J. Smola, P. L. Bartlett, B. Schölkopf, and D. Schuurmans, editors, Advances in Large Margin Classifiers, pages 221--246. MIT Press, 2000. [ bib ]
[83]	M. Anthony and P. L. Bartlett. Function learning from interpolation. Combinatorics, Probability, and Computing, 9:213--225, 2000. [ bib ]
[84]	Alexander J. Smola, Peter L. Bartlett, Bernard Schölkopf, and Dale Schuurmans, editors. Advances in Large Margin Classifiers. MIT Press, 2000. [ bib ]
[85]	A. J. Smola and P. L. Bartlett. Sparse greedy Gaussian process regression. In Advances in Neural Information Processing Systems 13, pages 619--625, 2001. [ bib ]
[86]	P. L. Bartlett and S. Mendelson. Rademacher and Gaussian complexities: Risk bounds and structural results. In Proceedings of the Fourteenth Annual Conference on Computational Learning Theory and Fifth European Conference on Computational Learning Theory, pages 224--240, 2001. [ bib ]
[87]	A. Ben-Hur, T. Barnes, P. L. Bartlett, O. Chapelle, A. Elisseeff, H. Fristche, I. Guyon, B. Schölkopf, J. Weston, E. Fung, C. Enderwick, E. A. Dalmasso, B.-L. Adam, J. W. Davis, A. Vlahou, L. Cazares, M. Ward, P. F. Schellhammer, J. Semmes, and G. L. Wright. Application of support vector machines to the classification of proteinchip system mass spectral data of prostate cancer serum samples (abstract). In Second Annual National Cancer Institute Early Detection Research Network Scientific Workshop, 2001. [ bib ]
[88]	J. Baxter, P. L. Bartlett, and L. Weaver. Experiments with infinite-horizon, policy-gradient estimation. Journal of Artificial Intelligence Research, 15:351--381, 2001. [ bib | .html ]
[89]	J. Baxter and P. L. Bartlett. Infinite-horizon policy-gradient estimation. Journal of Artificial Intelligence Research, 15:319--350, 2001. [ bib | .html ]
[90]	E. Greensmith, P. L. Bartlett, and J. Baxter. Variance reduction techniques for gradient estimates in reinforcement learning. In Advances in Neural Information Processing Systems 14, pages 1507--1514, 2002. [ bib | .ps.gz ]
[91]	G. Lanckriet, N. Cristianini, P. L. Bartlett, L. El Ghaoui, and M. Jordan. Learning the kernel matrix with semi-definite programming. In Proceedings of the International Conference on Machine Learning, pages 323--330, 2002. [ bib ]
[92]	P. L. Bartlett, O. Bousquet, and S. Mendelson. Localized Rademacher complexity. In Proceedings of the Conference on Computational Learning Theory, pages 44--58, 2002. [ bib ]
[93]	L. Mason, P. L. Bartlett, and M. Golea. Generalization error of combined classifiers. Journal of Computer and System Sciences, 65(2):415--438, 2002. [ bib | http ]
[94]	P. L. Bartlett, P. Fischer, and K.-U. Höffgen. Exploiting random walks for learning. Information and Computation, 176(2):121--135, 2002. [ bib | http ]
[95]	P. L. Bartlett and S. Ben-David. Hardness results for neural network approximation problems. Theoretical Computer Science, 284(1):53--66, 2002. (special issue on Eurocolt'99). [ bib | http ]
[96]	P. L. Bartlett and J. Baxter. Estimation and approximation bounds for gradient-based reinforcement learning. Journal of Computer and System Sciences, 64(1):133--150, 2002. [ bib ]
[97]	P. L. Bartlett, S. Boucheron, and G. Lugosi. Model selection and error estimation. Machine Learning, 48:85--113, 2002. [ bib | .ps.gz ]
[98]	P. L. Bartlett and S. Mendelson. Rademacher and Gaussian complexities: Risk bounds and structural results. Journal of Machine Learning Research, 3:463--482, 2002. [ bib | .pdf ]
[99]	Peter L. Bartlett and Evan Greensmith. Faster convergence rates for error probabilities of message passing decoders for low-density parity-check codes. Technical report, U.C. Berkeley, 2002. [ bib | .ps.Z | Abstract ]
[100]	Y. Guo, P. L. Bartlett, J. Shawe-Taylor, and R. C. Williamson. Covering numbers for support vector machines. IEEE Transactions on Information Theory, 48(1):239--250, 2002. [ bib ]
[101]	Peter L. Bartlett. An introduction to reinforcement learning theory: value function methods. In Shahar Mendelson and Alexander J. Smola, editors, Advanced Lectures on Machine Learning, volume 2600, pages 184--202. Springer, 2003. [ bib ]
[102]	Peter L. Bartlett and Wolfgang Maass. Vapnik-Chervonenkis dimension of neural nets. In Michael A. Arbib, editor, The Handbook of Brain Theory and Neural Networks, pages 1188--1192. MIT Press, 2003. Second Edition. [ bib | .ps.gz | .pdf ]
[103]	Peter L. Bartlett, Michael I. Jordan, and Jon D. McAuliffe. Convexity, classification, and risk bounds. Technical Report 638, Department of Statistics, U.C. Berkeley, 2003. [ bib | .ps.Z | .pdf | Abstract ]
[104]	Peter L. Bartlett. Prediction algorithms: complexity, concentration and convexity. In Proceedings of the 13th IFAC Symposium on System Identification, pages 1507--1517, 2003. [ bib | .ps.Z | Abstract ]
[105]	Peter L. Bartlett, Shahar Mendelson, and Petra Philips. Local complexities for empirical risk minimization. In Proceedings of the 17th Annual Conference on Computational Learning Theory (COLT2004), volume 3120, pages 270--284. Springer, 2004. [ bib | .ps.gz | .pdf | Abstract ]
[106]	Peter L. Bartlett and Ambuj Tewari. Sparseness vs estimating conditional probabilities: Some asymptotic results. In Proceedings of the 17th Annual Conference on Learning Theory, volume 3120, pages 564--578. Springer, 2004. [ bib | .ps.gz | .pdf | Abstract ]
[107]	Peter L. Bartlett, Michael I. Jordan, and Jon D. McAuliffe. Large margin classifiers: convex loss, low noise, and convergence rates. In Advances in Neural Information Processing Systems, 16, 2004. [ bib | .ps.gz | Abstract ]
[108]	Peter L. Bartlett, Michael I. Jordan, and Jon D. McAuliffe. Discussion of boosting papers. The Annals of Statistics, 32(1):85--91, 2004. [ bib | .ps.Z | .pdf ]
[109]	E. Greensmith, P. L. Bartlett, and J. Baxter. Variance reduction techniques for gradient estimates in reinforcement learning. Journal of Machine Learning Research, 5:1471--1530, 2004. [ bib | .pdf ]
[110]	G. Lanckriet, N. Cristianini, P. L. Bartlett, L. El Ghaoui, and M. Jordan. Learning the kernel matrix with semi-definite programming. Journal of Machine Learning Research, 5:27--72, 2004. [ bib | .ps.gz | .pdf ]
[111]	Peter L. Bartlett, Olivier Bousquet, and Shahar Mendelson. Local Rademacher complexities. Annals of Statistics, 33(4):1497--1537, 2005. [ bib | .ps | .pdf | Abstract ]
[112]	Rafael Jiménez-Rodriguez, Nicholas Sitar, and Peter L. Bartlett. Maximum likelihood estimation of trace length distribution parameters using the EM algorithm. In G. Barla and M. Barla, editors, Prediction, Analysis and Design in Geomechanical Applications: Proceedings of the Eleventh International Conference on Computer Methods and Advances in Geomechanics (IACMAG-2005), volume 1, pages 619--626, Bologna, 2005. Pàtron Editore. [ bib ]
[113]	Peter L. Bartlett, Michael Collins, Ben Taskar, and David McAllester. Exponentiated gradient algorithms for large-margin structured classification. In Lawrence K. Saul, Yair Weiss, and Léon Bottou, editors, Advances in Neural Information Processing Systems 17, pages 113--120, Cambridge, MA, 2005. MIT Press. [ bib | .ps.gz | .pdf | Abstract ]
[114]	Ambuj Tewari and Peter L. Bartlett. On the consistency of multiclass classification methods. In Proceedings of the 18th Annual Conference on Learning Theory, volume 3559, pages 143--157. Springer, 2005. [ bib | .pdf ]
[115]	Peter L. Bartlett and Shahar Mendelson. Discussion of “2004 IMS Medallion Lecture: Local Rademacher complexities and oracle inequalities in risk minimization” by V. Koltchinskii. The Annals of Statistics, 34(6):2657--2663, 2006. [ bib ]
[116]	Peter L. Bartlett and Mikhail Traskin. Adaboost and other large margin classifiers: Convexity in pattern classification. In Proceedings of the 5th Workshop on Defence Applications of Signal Processing, 2006. [ bib ]
[117]	Peter L. Bartlett, Michael I. Jordan, and Jon D. McAuliffe. Comment. Statistical Science, 21(3):341--346, 2006. [ bib ]
[118]	Peter L. Bartlett and Mikhail Traskin. Adaboost is consistent. Technical report, U. C. Berkeley, 2006. [ bib ]
[119]	Peter L. Bartlett and Marten H. Wegkamp. Classification with a reject option using a hinge loss. Technical report, U.C. Berkeley, 2006. [ bib | .ps.gz | .pdf | Abstract ]
[120]	Peter L. Bartlett and Shahar Mendelson. Empirical minimization. Probability Theory and Related Fields, 135(3):311--334, 2006. [ bib | .ps.gz | .pdf | Abstract ]
[121]	Peter L. Bartlett, Michael I. Jordan, and Jon D. McAuliffe. Convexity, classification, and risk bounds. Journal of the American Statistical Association, 101(473):138--156, 2006. (Was Department of Statistics, U.C. Berkeley Technical Report number 638, 2003). [ bib | .ps.gz | .pdf | Abstract ]
[122]	Michael Collins, Amir Globerson, Terry Koo, Xavier Carreras, and Peter L. Bartlett. Exponentiated gradient algorithms for conditional random fields and max-margin Markov networks. Technical report, U.C. Berkeley, 2007. [ bib | .pdf | Abstract ]
[123]	Jacob Duncan Abernethy, Peter L. Bartlett, and Alexander Rakhlin. Multitask learning with expert advice. Technical Report UCB/EECS-2007-20, EECS Department, University of California, Berkeley, 2007. [ bib | .html ]
[124]	Jacob Abernethy, Peter L. Bartlett, Alexander Rakhlin, and Ambuj Tewari. Minimax lower bounds for online convex games. Technical report, UC Berkeley, 2007. [ bib | .pdf | Abstract ]
[125]	David Rosenberg and Peter L. Bartlett. On bounds for Bayesian sequence prediction with non-Gaussian priors. Technical report, 2007. Technical Report. [ bib | Abstract ]
[126]	Benjamin I. P. Rubinstein, Peter L. Bartlett, and J. Hyam Rubinstein. Shifting: one-inclusion mistake bounds and sample compression. Technical report, EECS Department, University of California, Berkeley, 2007. [ bib | .pdf | Abstract ]
[127]	Peter L. Bartlett and Mikhail Traskin. Adaboost is consistent. Journal of Machine Learning Research, 8:2347--2368, 2007. [ bib | .pdf | .pdf | Abstract ]
[128]	Alexander Rakhlin, Jacob Abernethy, and Peter L. Bartlett. Online discovery of similarity mappings. In Proceedings of the 24th International Conference on Machine Learning (ICML-2007), pages 767--774, 2007. [ bib | Abstract ]
[129]	Jacob Abernethy, Peter L. Bartlett, and Alexander Rakhlin. Multitask learning with expert advice. In Proceedings of the Conference on Learning Theory, pages 484--498, 2007. [ bib | Abstract ]
[130]	Ambuj Tewari and Peter L. Bartlett. Bounded parameter Markov decision processes with average reward criterion. In Proceedings of the Conference on Learning Theory, pages 263--277, 2007. [ bib ]
[131]	Peter L. Bartlett and Mikhail Traskin. Adaboost is consistent. In B. Schölkopf, J. Platt, and T. Hoffman, editors, Advances in Neural Information Processing Systems 19, pages 105--112, Cambridge, MA, 2007. MIT Press. [ bib | .pdf | Abstract ]
[132]	David Rosenberg and Peter L. Bartlett. The Rademacher complexity of co-regularized kernel classes. In Marina Meila and Xiaotong Shen, editors, Proceedings of the Eleventh International Conference on Artificial Intelligence and Statistics, volume 2, pages 396--403, 2007. [ bib | .pdf | Abstract ]
[133]	Benjamin I. P. Rubinstein, Peter L. Bartlett, and J. Hyam Rubinstein. Shifting, one-inclusion mistake bounds and tight multiclass expected risk bounds. In B. Schölkopf, J. Platt, and T. Hoffman, editors, Advances in Neural Information Processing Systems 19, pages 1193--1200, Cambridge, MA, 2007. MIT Press. [ bib | .pdf ]
[134]	Peter L. Bartlett and Ambuj Tewari. Sample complexity of policy search with known dynamics. In B. Schölkopf, J. Platt, and T. Hoffman, editors, Advances in Neural Information Processing Systems 19, pages 97--104, Cambridge, MA, 2007. MIT Press. [ bib | .pdf ]
[135]	Peter L. Bartlett. Fast rates for estimation error and oracle inequalities for model selection. Technical Report 729, Department of Statistics, U.C. Berkeley, 2007. [ bib | .pdf | Abstract ]
[136]	Peter L. Bartlett, Shahar Mendelson, and Petra Philips. Optimal sample-based estimates of the expectation of the empirical minimizer. Technical report, U.C. Berkeley, 2007. [ bib | .ps.gz | .pdf | Abstract ]
[137]	Peter L. Bartlett and Ambuj Tewari. Sparseness vs estimating conditional probabilities: Some asymptotic results. Journal of Machine Learning Research, 8:775--790, April 2007. [ bib | .html ]
[138]	Ambuj Tewari and Peter L. Bartlett. On the consistency of multiclass classification methods. Journal of Machine Learning Research, 8:1007--1025, May 2007. (Invited paper). [ bib | .html ]
[139]	Alekh Agarwal, Alexander Rakhlin, and Peter Bartlett. Matrix regularization techniques for online multitask learning. Technical Report UCB/EECS-2008-138, EECS Department, University of California, Berkeley, 2008. [ bib | .pdf | Abstract ]
[140]	Peter L. Bartlett. Fast rates for estimation error and oracle inequalities for model selection. Econometric Theory, 24(2):545--552, April 2008. (Was Department of Statistics, U.C. Berkeley Technical Report number 729, 2007). [ bib | DOI | .pdf | Abstract ]
[141]	Michael Collins, Amir Globerson, Terry Koo, Xavier Carreras, and Peter L. Bartlett. Exponentiated gradient algorithms for conditional random fields and max-margin Markov networks. Journal of Machine Learning Research, 9:1775--1822, August 2008. [ bib | .pdf | Abstract ]
[142]	Peter L. Bartlett and Marten H. Wegkamp. Classification with a reject option using a hinge loss. Journal of Machine Learning Research, 9:1823--1840, August 2008. [ bib | .pdf | Abstract ]
[143]	Massieh Najafi, David M. Auslander, Peter L. Bartlett, and Philip Haves. Overcoming the complexity of diagnostic problems due to sensor network architecture. In K. Grigoriadis, editor, Proceedings of Intelligent Systems and Control (ISC 2008), pages 633--071, September 2008. [ bib ]
[144]	Massieh Najafi, David M. Auslander, Peter L. Bartlett, and Philip Haves. Fault diagnostics and supervised testing: How fault diagnostic tools can be proactive? In K. Grigoriadis, editor, Proceedings of Intelligent Systems and Control (ISC 2008), pages 633--034, September 2008. [ bib ]
[145]	Wee Sun Lee, Peter L. Bartlett, and Robert C. Williamson. Correction to the importance of convexity in learning with squared loss. IEEE Transactions on Information Theory, 54(9):4395, September 2008. [ bib | .pdf ]
[146]	Ambuj Tewari and Peter L. Bartlett. Optimistic linear programming gives logarithmic regret for irreducible MDPs. In John Platt, Daphne Koller, Yoram Singer, and Sam Roweis, editors, Advances in Neural Information Processing Systems 20, pages 1505--1512, Cambridge, MA, September 2008. MIT Press. [ bib | .pdf | Abstract ]
[147]	Peter L. Bartlett, Elad Hazan, and Alexander Rakhlin. Adaptive online gradient descent. In John Platt, Daphne Koller, Yoram Singer, and Sam Roweis, editors, Advances in Neural Information Processing Systems 20, pages 65--72, Cambridge, MA, September 2008. MIT Press. [ bib | .pdf | Abstract ]
[148]	Marco Barreno, Peter L. Bartlett, F. J. Chi, Anthony D. Joseph, Blaine Nelson, Benjamin I. P. Rubinstein, U. Saini, and J. Doug Tygar. Open problems in the security of learning. In Proceedings of the 1st ACM Workshop on AISec (AISec2008), pages 19--26, October 2008. [ bib | DOI ]
[149]	Massieh Najafi, David M. Auslander, Peter L. Bartlett, and Philip Haves. Application of machine learning in fault diagnostics of mechanical systems. In Proceedings of the World Congress on Engineering and Computer Science 2008: International Conference on Modeling, Simulation and Control 2008, pages 957--962, October 2008. [ bib | .pdf ]
[150]	Jacob Abernethy, Peter L. Bartlett, Alexander Rakhlin, and Ambuj Tewari. Optimal strategies and minimax lower bounds for online convex games. In Proceedings of the 21st Annual Conference on Learning Theory (COLT 2008), pages 415--423, December 2008. [ bib | .pdf ]
[151]	Peter L. Bartlett, Varsha Dani, Thomas Hayes, Sham Kakade, Alexander Rakhlin, and Ambuj Tewari. High-probability regret bounds for bandit online linear optimization. In Proceedings of the 21st Annual Conference on Learning Theory (COLT 2008), pages 335--342, December 2008. [ bib | .pdf ]
[152]	Benjamin I. P. Rubinstein, Peter L. Bartlett, Ling Huang, and Nina Taft. Learning in a large function space: Privacy preserving mechanisms for SVM learning. Technical Report 0911.5708, arxiv.org, 2009. [ bib | http | Abstract ]
[153]	A. Barth, Benjamin I. P. Rubinstein, M. Sundararajan, J. C. Mitchell, Dawn Song, and Peter L. Bartlett. A learning-based approach to reactive security. Technical Report 0912.1155, arxiv.org, 2009. [ bib | http | Abstract ]
[154]	Jacob Abernethy, Alekh Agarwal, Peter L. Bartlett, and Alexander Rakhlin. A stochastic view of optimal regret through minimax duality. Technical Report 0903.5328, arxiv.org, 2009. [ bib | http | Abstract ]
[155]	Benjamin I. P. Rubinstein, Peter L. Bartlett, and J. Hyam Rubinstein. Shifting: one-inclusion mistake bounds and sample compression. Journal of Computer and System Sciences, 75(1):37--59, January 2009. (Was University of California, Berkeley, EECS Department Technical Report EECS-2007-86). [ bib | .pdf ]
[156]	Alekh Agarwal, Peter L. Bartlett, Pradeep Ravikumar, and Martin Wainwright. Information-theoretic lower bounds on the oracle complexity of convex optimization. In Y. Bengio, D. Schuurmans, J. Lafferty, C. K. I. Williams, and A. Culotta, editors, Advances in Neural Information Processing Systems 22, pages 1--9, June 2009. [ bib | .pdf | Abstract ]
[157]	Jacob Abernethy, Alekh Agarwal, Peter L. Bartlett, and Alexander Rakhlin. A stochastic view of optimal regret through minimax duality. In Proceedings of the 22nd Annual Conference on Learning Theory -- COLT 2009, pages 257--266, June 2009. [ bib | .pdf | Abstract ]
[158]	Peter L. Bartlett and Ambuj Tewari. REGAL: A regularization based algorithm for reinforcement learning in weakly communicating MDPs. In Proceedings of the 25th Conference on Uncertainty in Artificial Intelligence (UAI2009), pages 35--42, June 2009. [ bib | .pdf ]
[159]	David S. Rosenberg, Vikas Sindhwani, Peter L. Bartlett, and Partha Niyogi. Multiview point cloud kernels for semisupervised learning. IEEE Signal Processing Magazine, 26(5):145--150, September 2009. [ bib | DOI ]
[160]	Peter L. Bartlett, Shahar Mendelson, and Petra Philips. On the optimality of sample-based estimates of the expectation of the empirical minimizer. ESAIM: Probability and Statistics, 14:315--337, January 2010. [ bib | .pdf | Abstract ]
[161]	A. Barth, Benjamin I. P. Rubinstein, M. Sundararajan, J. C. Mitchell, Dawn Song, and Peter L. Bartlett. A learning-based approach to reactive security. In Proceedings of Financial Cryptography and Data Security (FC10), pages 192--206, 2010. [ bib | DOI ]
[162]	Jacob Abernethy, Peter L. Bartlett, and Elad Hazan. Blackwell approachability and no-regret learning are equivalent. Technical Report 1011.1936, arxiv.org, 2010. [ bib | http | Abstract ]
[163]	Marius Kloft, Ulrich Rückert, and Peter L. Bartlett. A unifying view of multiple kernel learning. Technical Report 1005.0437, arxiv.org, 2010. [ bib | http | Abstract ]
[164]	Benjamin I. P. Rubinstein, Peter L. Bartlett, and J. Hyam Rubinstein. Corrigendum to `shifting: One-inclusion mistake bounds and sample compression' [J. Comput. System Sci 75 (1) (2009) 37-59]. Journal of Computer and System Sciences, 76(3--4):278--280, May 2010. [ bib | DOI ]
[165]	Peter L. Bartlett. Learning to act in uncertain environments. Communications of the ACM, 53(5):98, May 2010. (Invited one-page comment). [ bib | DOI ]
[166]	Alekh Agarwal, Peter L. Bartlett, and Max Dama. Optimal allocation strategies for the dark pool problem. In Y. W. Teh and M. Titterington, editors, Proceedings of The Thirteenth International Conference on Artificial Intelligence and Statistics (AISTATS), volume 9, pages 9--16, May 2010. [ bib | .pdf | Abstract ]
[167]	Brian Kulis and Peter L. Bartlett. Implicit online learning. In Johannes Fürnkranz and Thorsten Joachims, editors, Proceedings of the 27th International Conference on Machine Learning (ICML-10), pages 575--582, June 2010. [ bib | .pdf ]
[168]	Marius Kloft, Ulrich Rückert, and Peter L. Bartlett. A unifying view of multiple kernel learning. In José L. Balcázar, Francesco Bonchi, Aristides Gionis, and Michèle Sebag, editors, Machine Learning and Knowledge Discovery in Databases, European Conference, ECML PKDD, pages 66--81, September 2010. Part II, LNAI 6322. [ bib | DOI ]
[169]	Peter L. Bartlett. Optimal online prediction in adversarial environments. In Marcus Hutter, Frank Stephan, Vladimir Vovk, and Thomas Zeugmann, editors, Algorithmic Learning Theory, 21st International Conference, ALT 2010, page 34, October 2010. (Plenary talk abstract). [ bib | DOI ]
[170]	Jacob Abernethy, Peter L. Bartlett, Niv Buchbinder, and Isabelle Stanton. A regularization approach to metrical task systems. In Marcus Hutter, Frank Stephan, Vladimir Vovk, and Thomas Zeugmann, editors, Algorithmic Learning Theory, 21st International Conference, ALT 2010, pages 270--284, October 2010. [ bib | DOI ]
[171]	Sylvain Arlot and Peter L. Bartlett. Margin-adaptive model selection in statistical learning. Bernoulli, 17(2):687--713, May 2011. [ bib | .pdf | Abstract ]
[172]	Alekh Agarwal, John Duchi, Peter L. Bartlett, and Clement Levrard. Oracle inequalities for computationally budgeted model selection. In Sham Kakade and Ulrike von Luxburg, editors, Proceedings of the Conference on Learning Theory (COLT2011), volume 19, pages 69--86, July 2011. [ bib | .pdf | Abstract ]
[173]	Jacob Abernethy, Peter L. Bartlett, and Elad Hazan. Blackwell approachability and no-regret learning are equivalent. In Sham Kakade and Ulrike von Luxburg, editors, Proceedings of the Conference on Learning Theory (COLT2011), volume 19, pages 27--46, July 2011. [ bib | .pdf | Abstract ]
[174]	Afshin Rostamizadeh, Alekh Agarwal, and Peter L. Bartlett. Learning with missing features. In Avi Pfeffer and Fabio G. Cozman, editors, Proceedings of the Conference on Uncertainty in Artificial Intelligence (UAI2011), pages 635--642, July 2011. [ bib | .pdf | Abstract ]
[175]	John Shawe-Taylor, Richard Zemel, Peter L. Bartlett, Fernando Pereira, and Kilian Weinberger, editors. Advances in Neural Information Processing Systems 24. Proceedings of the 2011 Conference. NIPS Foundation, December 2011. [ bib | .html ]
[176]	John C. Duchi, Peter L. Bartlett, and Martin J. Wainwright. Randomized Smoothing for (Parallel) Stochastic Optimization. In 2012 IEEE 51st Annual Conference on Decision and Control (CDC), IEEE Conference on Decision and Control, pages 5442--5444, 345 E 47th St, New York, NY 10017 USA, 2012. IEEE. [ bib | Abstract ]
[177]	Alekh Agarwal, Peter L. Bartlett, and John Duchi. Oracle inequalities for computationally adaptive model selection. Technical Report 1208.0129, arxiv.org, 2012. [ bib | http | Abstract ]
[178]	Fares Hedayati and Peter L. Bartlett. Exchangeability characterizes optimality of sequential normalized maximum likelihood and Bayesian prediction with Jeffreys prior. In M. Girolami and N. Lawrence, editors, Proceedings of the Fifteenth International Conference on Artificial Intelligence and Statistics (AISTATS), volume 22, pages 504--510, April 2012. [ bib | .pdf | Abstract ]
[179]	Alekh Agarwal, Peter Bartlett, Pradeep Ravikumar, and Martin Wainwright. Information-theoretic lower bounds on the oracle complexity of stochastic convex optimization. IEEE Transactions on Information Theory, 58(5):3235--3249, May 2012. [ bib | DOI | .pdf | Abstract ]
[180]	Fares Hedayati and Peter Bartlett. The optimality of Jeffreys prior for online density estimation and the asymptotic normality of maximum likelihood estimators. In Proceedings of the Conference on Learning Theory (COLT2012), volume 23, pages 7.1--7.13, June 2012. [ bib | .pdf | Abstract ]
[181]	John Duchi, Peter L. Bartlett, and Martin J. Wainwright. Randomized smoothing for stochastic optimization. SIAM Journal on Optimization, 22(2):674--701, June 2012. [ bib | .pdf | Abstract ]
[182]	A. Barth, Benjamin I. P. Rubinstein, M. Sundararajan, J. C. Mitchell, Dawn Song, and Peter L. Bartlett. A learning-based approach to reactive security. IEEE Transactions on Dependable and Secure Computing, 9(4):482--493, July 2012. [ bib | http | .pdf | Abstract ]
[183]	Massieh Najafi, David M. Auslander, Peter L. Bartlett, Philip Haves, and Michael D. Sohn. Application of machine learning in the fault diagnostics of air handling units. Applied Energy, 96:347--358, August 2012. [ bib | DOI ]
[184]	Benjamin I. P. Rubinstein, Peter L. Bartlett, Ling Huang, and Nina Taft. Learning in a large function space: Privacy preserving mechanisms for SVM learning. Journal of Privacy and Confidentiality, 4(1):65--100, August 2012. [ bib | http | Abstract ]
[185]	Peter L. Bartlett, Shahar Mendelson, and Joseph Neeman. l1-regularized linear regression: Persistence and oracle inequalities. Probability Theory and Related Fields, 154(1--2):193--224, October 2012. [ bib | DOI | .pdf | Abstract ]
[186]	Peter L. Bartlett, Fernando Pereira, Chris J. C. Burges, Léon Bottou, and Kilian Q. Weinberger, editors. Advances in Neural Information Processing Systems 25. Proceedings of the 2012 Conference. NIPS Foundation, December 2012. [ bib | .html ]
[187]	Yasin Abbasi-Yadkori, Peter L. Bartlett, Varun Kanade, Yevgeny Seldin, and Csaba Szepesvari. Online learning in Markov decision processes with adversarially chosen transition probability distributions. In Advances in Neural Information Processing Systems 26, pages 2508--2516, 2013. [ bib | http | .pdf | Abstract ]
[188]	Jacob Abernethy, Peter L. Bartlett, Rafael Frongillo, and Andre Wibisono. How to hedge an option against an adversary: Black-Scholes pricing is minimax optimal. In Advances in Neural Information Processing Systems 26, pages 2346--2354, 2013. [ bib | http | .pdf | Abstract ]
[189]	Yevgeny Seldin, Koby Crammer, and Peter L Bartlett. Open problem: Adversarial multiarmed bandits with limited advice. In Proceedings of the Conference on Learning Theory (COLT2013), volume 30, pages 1067--1072, 2013. [ bib | .pdf ]
[190]	Peter L. Bartlett, Peter Grunwald, Peter Harremoes, Fares Hedayati, and Wojciech Kotlowski. Horizon-independent optimal prediction with log-loss in exponential families. In Proceedings of the Conference on Learning Theory (COLT2013), volume 30, pages 639--661, 2013. [ bib | .pdf | Abstract ]
[191]	Alex Kantchelian, Michael C Tschantz, Ling Huang, Peter L Bartlett, Anthony D Joseph, and J. Doug Tygar. Large-margin convex polytope machine. In Z. Ghahramani, M. Welling, C. Cortes, N.D. Lawrence, and K.Q. Weinberger, editors, Advances in Neural Information Processing Systems 27, pages 3248--3256. Curran Associates, Inc., 2014. [ bib | .pdf | Abstract ]
[192]	Wouter M Koolen, Alan Malek, and Peter L Bartlett. Efficient minimax strategies for square loss games. In Z. Ghahramani, M. Welling, C. Cortes, N.D. Lawrence, and K.Q. Weinberger, editors, Advances in Neural Information Processing Systems 27, pages 3230--3238. Curran Associates, Inc., 2014. [ bib | .pdf | Abstract ]
[193]	Yasin Abbasi-Yadkori, Peter L. Bartlett, and Alan Malek. Linear programming for large-scale Markov decision problems. In Proceedings of the 31st International Conference on Machine Learning (ICML-14), pages 496--504, 2014. [ bib | .html | .pdf | Abstract ]
[194]	Yasin Abbasi-Yadkori, Peter L. Bartlett, and Alan Malek. Linear programming for large-scale Markov decision problems. Technical Report 1402.6763, arXiv.org, 2014. [ bib | http | Abstract ]
[195]	J. Hyam Rubinstein, Benjamin Rubinstein, and Peter Bartlett. Bounding embeddings of VC classes into maximum classes. In A. Gammerman and V. Vovk, editors, Festschrift of Alexey Chervonenkis. Springer, 2014. [ bib | http | Abstract ]
[196]	J. Hyam Rubinstein, Benjamin Rubinstein, and Peter Bartlett. Bounding embeddings of VC classes into maximum classes. Technical Report 1401.7388, arXiv.org, 2014. [ bib | http | Abstract ]
[197]	Yasin Abbasi-Yadkori, Peter L. Bartlett, and Varun Kanade. Tracking adversarial targets. In Proceedings of the 31st International Conference on Machine Learning (ICML-14), pages 369--377, 2014. [ bib | .html | .pdf | Abstract ]
[198]	Yevgeny Seldin, Peter L. Bartlett, Koby Crammer, and Yasin Abbasi-Yadkori. Prediction with limited advice and multiarmed bandits with paid observations. In Proceedings of the 31st International Conference on Machine Learning (ICML-14), pages 280--287, 2014. [ bib | .html | .pdf | Abstract ]
[199]	Ambuj Tewari and Peter L. Bartlett. Learning theory. In Paulo S.R. Diniz, Johan A.K. Suykens, Rama Chellappa, and Sergios Theodoridis, editors, Signal Processing Theory and Machine Learning, volume 1 of Academic Press Library in Signal Processing, pages 775--816. Elsevier, 2014. [ bib ]
[200]	Yasin Abbasi-Yadkori, Peter L. Bartlett, and Stephen Wright. A Lagrangian relaxation approach to Markov decision problems. Technical report, UC Berkeley EECS, 2015. [ bib | Abstract ]
[201]	Walid Krichene, Alexandre Bayen, and Peter L. Bartlett. Accelerating mirror descent in continuous and discrete time. In C. Cortes, N.D. Lawrence, D.D. Lee, M. Sugiyama, R. Garnett, and R. Garnett, editors, Advances in Neural Information Processing Systems 28, pages 2827--2835. Curran Associates, Inc., 2015. [ bib | .pdf | Abstract ]
[202]	Walid Krichene, Alexandre Bayen, and Peter L. Bartlett. Accelerating mirror descent in continuous and discrete time. Technical report, EECS Department, University of California, Berkeley, 2015. [ bib ]
[203]	Yasin Abbasi-Yadkori, Wouter Koolen, Alan Malek, and Peter L. Bartlett. Minimax time series prediction. Technical report, EECS Department, University of California, Berkeley, 2015. [ bib ]
[204]	Wouter Koolen, Alan Malek, Peter L. Bartlett, and Yasin Abbasi-Yadkori. Minimax time series prediction. In C. Cortes, N.D. Lawrence, D.D. Lee, M. Sugiyama, R. Garnett, and R. Garnett, editors, Advances in Neural Information Processing Systems 28, pages 2548--2556. Curran Associates, Inc., 2015. [ bib | .pdf | Abstract ]
[205]	Peter L. Bartlett, Wouter Koolen, Alan Malek, Eiji Takimoto, and Manfred Warmuth. Minimax fixed-design linear regression. In Proceedings of the Conference on Learning Theory (COLT2015), volume 40, pages 226--239, June 2015. [ bib | .pdf | .pdf | Abstract ]
[206]	Yasin Abbasi-Yadkori, Peter L Bartlett, Xi Chen, and Alan Malek. Large-scale Markov decision problems with KL control cost. In Proceedings of the 32nd International Conference on Machine Learning (ICML-15), volume 37, pages 1053--1062, June 2015. [ bib | .html | .pdf | Abstract ]
[207]	Walid Krichene, Alexandre Bayen, and Peter L. Bartlett. Adaptive averaging in accelerated descent dynamics. In Advances in Neural Information Processing Systems 29, pages 2991--2999, 2016. [ bib | http | .pdf | Abstract ]
[208]	Victor Gabillon, Alessandro Lazaric, Mohammad Ghavamzadeh, Ronald Ortner, and Peter L. Bartlett. Improved learning complexity in combinatorial pure exploration bandits. In Proceedings of AISTATS 2016, pages 1004--1012, 2016. [ bib | .html | .pdf | Abstract ]
[209]	Yasin Abbasi-Yadkori, Peter L. Bartlett, and Stephen Wright. A fast and reliable policy improvement algorithm. In Proceedings of AISTATS 2016, pages 1338--1346, 2016. [ bib | .html | .pdf | Abstract ]
[210]	Niladri Chatterji and Peter Bartlett. Alternating minimization for dictionary learning with random initialization. In I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett, editors, Advances in Neural Information Processing Systems 30, pages 1997--2006. Curran Associates, Inc., 2017. [ bib | .pdf | .pdf ]
[211]	Walid Krichene and Peter Bartlett. Acceleration and averaging in stochastic descent dynamics. In I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett, editors, Advances in Neural Information Processing Systems 30, pages 6796--6806. Curran Associates, Inc., 2017. [ bib | .pdf | .pdf | Abstract ]
[212]	Peter L. Bartlett, Nick Harvey, Chris Liaw, and Abbas Mehrabian. Nearly-tight VC-dimension and pseudodimension bounds for piecewise linear neural networks. Technical Report 1703.02930, arXiv.org, 2017. [ bib | http | .pdf | Abstract ]
[213]	Peter Bartlett, Dylan Foster, and Matus Telgarsky. Spectrally-normalized margin bounds for neural networks. In I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett, editors, Advances in Neural Information Processing Systems 30, pages 6240--6249. Curran Associates, Inc., 2017. [ bib | .pdf | .pdf | Abstract ]
[214]	Yasin Abbasi-Yadkori, Peter L. Bartlett, and Victor Gabillon. Near minimax optimal players for the finite-time 3-expert prediction problem. In I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett, editors, Advances in Neural Information Processing Systems 30, pages 3033--3042. Curran Associates, Inc., 2017. [ bib | .pdf | .pdf | Abstract ]
[215]	Martin Péron, Kai Helge Becker, Peter L. Bartlett, and Iadine Chadès. Fast-tracking stationary MOMDPs for adaptive management problems. In Proceedings of the Thirty-First AAAI Conference on Artificial Intelligence (AAAI-17), pages 4531--4537, 2017. [ bib | http | http | Abstract ]
[216]	Kai Zhong, Zhao Song, Prateek Jain, Peter L. Bartlett, and Inderjit S. Dhillon. Recovery guarantees for one-hidden-layer neural networks. In Doina Precup and Yee Whye Teh, editors, Proceedings of the 34th International Conference on Machine Learning (ICML-17), volume 70 of Proceedings of Machine Learning Research, pages 4140--4149. PMLR, 2017. [ bib | .html | .pdf | Abstract ]
[217]	Yasin Abbasi-Yadkori, Alan Malek, Peter L. Bartlett, and Victor Gabillon. Hit-and-run for sampling and planning in non-convex spaces. In Aarti Singh and Jerry Zhu, editors, Proceedings of the 20th International Conference on Artificial Intelligence and Statistics, volume 54 of Proceedings of Machine Learning Research, pages 888--895, Fort Lauderdale, FL, USA, 2017. [ bib | .pdf | Abstract ]
[218]	Fares Hedayati and Peter L. Bartlett. Exchangeability characterizes optimality of sequential normalized maximum likelihood and Bayesian prediction. IEEE Transactions on Information Theory, 63(10):6767--6773, October 2017. [ bib | DOI | .pdf | .pdf | Abstract ]
[219]	Yi-An Ma, Xiang Cheng, Niladri S. Chatterji, Nicolas Flammarion, Peter L. Bartlett, and Michael I. Jordan. Underdamped Langevin algorithm as accelerated gradient descent for KL-divergence. Technical report, 2018. [ bib ]
[220]	Xiang Cheng, Niladri S. Chatterji, Yasin Abbasi-Yadkori, Peter L. Bartlett, and Michael I. Jordan. Sharp convergence rates for Langevin dynamics in the nonconvex setting. Technical Report arXiv:1805.01648 [stat.ML], arxiv.org, 2018. [ bib | http ]
[221]	Kush Bhatia, Aldo Pacchiano, Nicolas Flammarion, Peter L. Bartlett, and Michael I. Jordan. Gen-Oja: Simple and efficient algorithm for streaming generalized eigenvector computation. In S. Bengio, H. Wallach, H. Larochelle, K. Grauman, N. Cesa-Bianchi, and R. Garnett, editors, Advances in Neural Information Processing Systems 31, pages 7016--7025. Curran Associates, Inc., 2018. [ bib | .pdf | Abstract ]
[222]	Alan Malek and Peter L. Bartlett. Horizon-independent minimax linear regression. In S. Bengio, H. Wallach, H. Larochelle, K. Grauman, N. Cesa-Bianchi, and R. Garnett, editors, Advances in Neural Information Processing Systems 31, pages 5264--5273. Curran Associates, Inc., 2018. [ bib | .pdf | Abstract ]
[223]	Yasin Abbasi-Yadkori, Peter L. Bartlett, Victor Gabillon, Alan Malek, and Michal Valko. Best of both worlds: Stochastic and adversarial best-arm identification. In Sébastien Bubeck, Vianney Perchet, and Philippe Rigollet, editors, Proceedings of the 31st Conference on Learning Theory (COLT2018), volume 75 of Proceedings of Machine Learning Research, pages 918--949. PMLR, 2018. [ bib | http | .pdf | Abstract ]
[224]	Xiang Cheng, Niladri S. Chatterji, Peter L. Bartlett, and Michael I. Jordan. Underdamped Langevin MCMC: A non-asymptotic analysis. In Sébastien Bubeck, Vianney Perchet, and Philippe Rigollet, editors, Proceedings of the 31st Conference on Learning Theory (COLT2018), volume 75 of Proceedings of Machine Learning Research, pages 300--323. PMLR, 2018. [ bib | .html | .pdf | Abstract ]
[225]	Peter L. Bartlett, David P. Helmbold, and Philip M. Long. Gradient descent with identity initialization efficiently learns positive definite linear transformations by deep residual networks. In Jennifer Dy and Andreas Krause, editors, Proceedings of the 35th International Conference on Machine Learning (ICML-18), volume 80 of Proceedings of Machine Learning Research, pages 521--530. PMLR, 2018. [ bib | http | .pdf | Abstract ]
[226]	Niladri Chatterji, Nicolas Flammarion, Yian Ma, Peter Bartlett, and Michael Jordan. On the theory of variance reduction for stochastic gradient Monte Carlo. In Jennifer Dy and Andreas Krause, editors, Proceedings of the 35th International Conference on Machine Learning (ICML-18), volume 80 of Proceedings of Machine Learning Research, pages 764--773. PMLR, 2018. [ bib | .html | .pdf | Abstract ]
[227]	Dong Yin, Yudong Chen, Kannan Ramchandran, and Peter Bartlett. Byzantine-robust distributed learning: Towards optimal statistical rates. In Jennifer Dy and Andreas Krause, editors, Proceedings of the 35th International Conference on Machine Learning (ICML-18), volume 80 of Proceedings of Machine Learning Research, pages 5650--5659. PMLR, 2018. [ bib | .html | .pdf | Abstract ]
[228]	Martin Péron, Peter Bartlett, Kai Helge Becker, Kate Helmstedt, and Iadine Chadès. Two approximate dynamic programming algorithms for managing complete SIS networks. In ACM SIGCAS Conference on Computing and Sustainable Societies (COMPASS 2018), 2018. [ bib | http | .pdf ]
[229]	Xiang Cheng and Peter Bartlett. Convergence of Langevin MCMC in KL-divergence. In Firdaus Janoos, Mehryar Mohri, and Karthik Sridharan, editors, Proceedings of ALT2018, volume 83 of Proceedings of Machine Learning Research, pages 186--211. PMLR, 2018. [ bib | .html | .pdf | Abstract ]
[230]	Xiang Cheng, Fred Roosta, Stefan Palombo, Peter Bartlett, and Michael Mahoney. Flag n’ flare: Fast linearly-coupled adaptive gradient methods. In Amos Storkey and Fernando Perez-Cruz, editors, Proceedings of the 21st International Conference on Artificial Intelligence and Statistics, volume 84 of Proceedings of Machine Learning Research, pages 404--414. PMLR, 2018. [ bib | .html | .pdf | Abstract ]
[231]	Dong Yin, Ashwin Pananjady, Max Lam, Dimitris Papailiopoulos, Kannan Ramchandran, and Peter Bartlett. Gradient diversity: a key ingredient for scalable distributed learning. In Amos Storkey and Fernando Perez-Cruz, editors, Proceedings of the 21st International Conference on Artificial Intelligence and Statistics, volume 84 of Proceedings of Machine Learning Research, pages 1998--2007. PMLR, 2018. [ bib | .html | .pdf | Abstract ]
[232]	Peter L. Bartlett, Steven Evans, and Philip M. Long. Representing smooth functions as compositions of near-identity functions with implications for deep network optimization. Technical Report 1804.05012, arXiv.org, 2018. [ bib | http | .pdf | Abstract ]
[233]	Xiang Cheng, Dong Yin, Peter L. Bartlett, and Michael I. Jordan. Quantitative w1 convergence of Langevin-like stochastic processes with non-convex potential and state-dependent noise. Technical Report arXiv:1907.03215, arxiv.org, 2019. [ bib | http ]
[234]	Xiang Cheng, Dong Yin, Peter L. Bartlett, and Michael Jordan. Non-asymptotic convergence of stochastic processes with state-dependent noise. Technical report, UC Berkeley, 2019. [ bib ]
[235]	Wenlong Mou, Nicolas Flammarion, Martin Wainwright, and Peter L. Bartlett. An efficient sampling algorithm for non-smooth composite potentials. Technical report, UC Berkeley, 2019. [ bib ]
[236]	Wenlong Mou, Yian Ma, Peter L. Bartlett, Michael Jordan, and Martin Wainwright. High-order Langevin algorithms can accelerate the convergence of MCMC. Technical report, UC Berkeley, 2019. [ bib ]
[237]	Xiang Cheng, Peter L. Bartlett, and Michael I. Jordan. Quantitative weak convergence for discrete stochastic processes. Technical Report arXiv:1902.00832, arxiv.org, 2019. [ bib | http ]
[238]	Peter L. Bartlett, Philip M. Long, Gábor Lugosi, and Alexander Tsigler. Benign overfitting in linear regression. Technical Report arXiv:1906.11300 [stat.ML], arxiv.org, 2019. [ bib | http ]
[239]	Peter L. Bartlett, David P. Helmbold, and Philip M. Long. Gradient descent with identity initialization efficiently learns positive definite linear transformations by deep residual networks. Neural Computation, 31:477--502, 2019. [ bib ]
[240]	Yeshwanth Cherapanamjeri and Peter L. Bartlett. Testing Markov chains without hitting. In Alina Beygelzimer and Daniel Hsu, editors, Proceedings of the 32nd Conference on Learning Theory (COLT2019), volume 99 of Proceedings of Machine Learning Research, pages 758--785. PMLR, 2019. [ bib | .html | .pdf | Abstract ]
[241]	Yeshwanth Cherapanamjeri, Nicolas Flammarion, and Peter L. Bartlett. Fast mean estimation with sub-gaussian rates. In Alina Beygelzimer and Daniel Hsu, editors, Proceedings of the Thirty-Second Conference on Learning Theory, volume 99 of Proceedings of Machine Learning Research, pages 786--806. PMLR, 2019. [ bib | .html | .pdf | Abstract ]
[242]	Dong Yin, Ramchandran Kannan, and Peter L. Bartlett. Rademacher complexity for adversarially robust generalization. In Kamalika Chaudhuri and Ruslan Salakhutdinov, editors, Proceedings of the 36th International Conference on Machine Learning, volume 97 of Proceedings of Machine Learning Research, pages 7085--7094, Long Beach, California, USA, 2019. PMLR. [ bib | .html | .pdf | Abstract ]
[243]	Dong Yin, Yudong Chen, Ramchandran Kannan, and Peter L. Bartlett. Defending against saddle point attack in Byzantine-robust distributed learning. In Kamalika Chaudhuri and Ruslan Salakhutdinov, editors, Proceedings of the 36th International Conference on Machine Learning, volume 97 of Proceedings of Machine Learning Research, pages 7074--7084, Long Beach, California, USA, 2019. PMLR. [ bib | .html | .pdf | Abstract ]
[244]	Yasin Abbasi-Yadkori, Peter L. Bartlett, Kush Bhatia, Nevena Lazic, Csaba Szepesvari, and Gellert Weisz. POLITEX: Regret bounds for policy iteration using expert prediction. In Kamalika Chaudhuri and Ruslan Salakhutdinov, editors, Proceedings of the 36th International Conference on Machine Learning, volume 97 of Proceedings of Machine Learning Research, pages 3692--3702, Long Beach, California, USA, 2019. PMLR. [ bib | .html | .pdf | Abstract ]
[245]	Peter L. Bartlett, Victor Gabillon, Jennifer Healey, and Michal Valko. Scale-free adaptive planning for deterministic dynamics and discounted rewards. In Kamalika Chaudhuri and Ruslan Salakhutdinov, editors, Proceedings of the 36th International Conference on Machine Learning, volume 97 of Proceedings of Machine Learning Research, pages 495--504, Long Beach, California, USA, 2019. PMLR. [ bib | .html | .pdf | Abstract ]
[246]	Niladri Chatterji, Aldo Pacchiano, and Peter Bartlett. Online learning with kernel losses. In Kamalika Chaudhuri and Ruslan Salakhutdinov, editors, Proceedings of the 36th International Conference on Machine Learning, volume 97 of Proceedings of Machine Learning Research, pages 971--980, Long Beach, California, USA, 2019. PMLR. [ bib | .html | .pdf | Abstract ]
[247]	Vidya Muthukumar, Mitas Ray, Anant Sahai, and Peter L. Bartlett. Best of many worlds: Robust model selection for online supervised learning. In Kamalika Chaudhuri and Masashi Sugiyama, editors, Proceedings of the 22nd International Conference on Artificial Intelligence and Statistics (AISTATS), volume 89 of Proceedings of Machine Learning Research, pages 3177--3186. PMLR, 2019. [ bib | .html | .pdf | Abstract ]
[248]	Dhruv Malik, Ashwin Pananjady, Kush Bhatia, Koulik Khamaru, Peter L. Bartlett, and Martin J. Wainwright. Derivative-free methods for policy optimization: Guarantees for linear quadratic systems. In Kamalika Chaudhuri and Masashi Sugiyama, editors, Proceedings of the 22nd International Conference on Artificial Intelligence and Statistics (AISTATS), volume 89 of Proceedings of Machine Learning Research, pages 2916--2925. PMLR, 2019. [ bib | .html | .pdf | Abstract ]
[249]	Peter L. Bartlett, Victor Gabillon, and Michal Valko. A simple parameter-free and adaptive approach to optimization under a minimal local smoothness assumption. In Aurélien Garivier and Satyen Kale, editors, Proceedings of the 30th International Conference on Algorithmic Learning Theory, volume 98 of Proceedings of Machine Learning Research, pages 184--206, Chicago, Illinois, 2019. PMLR. [ bib | .html | .pdf | Abstract ]
[250]	Peter L. Bartlett, Nick Harvey, Christopher Liaw, and Abbas Mehrabian. Nearly-tight VC-dimension and pseudodimension bounds for piecewise linear neural networks. Journal of Machine Learning Research, 20(63):1--17, 2019. [ bib | .html ]
[251]	Peter L. Bartlett and Philip M. Long. Failures of model-dependent generalization bounds for least-norm interpolation. Technical Report arXiv:2010.08479, arxiv.org, 2020. [ bib | http | Abstract ]
[252]	Hossein Mobahi, Mehrdad Farajtabar, and Peter L. Bartlett. Self-distillation amplifies regularization in Hilbert space. In Advances in Neural Information Processing Systems 33, 2020. [ bib | Abstract ]
[253]	Kush Bhatia, Ashwin Pananjady, Peter L. Bartlett, Anca Dragan, and Martin Wainwright. Preference learning along multiple criteria: A game-theoretic perspective. In Advances in Neural Information Processing Systems 33, 2020. [ bib | Abstract ]
[254]	Alexander Tsigler and Peter L. Bartlett. Benign overfitting in ridge regression. Technical Report arXiv:2009.14286, arxiv.org, 2020. [ bib | http | Abstract ]
[255]	Wenlong Mou, Junchi Li, Martin Wainwright, Peter L. Bartlett, and Michael I. Jordan. Fine-grained analysis for linear stochastic approximation with averaging: Polyak-Ruppert, non-asymptotic concentration and beyond. In Proceedings of the 33nd Conference on Learning Theory (COLT2020), 2020. [ bib ]
[256]	Jonathan Lee, Aldo Pacchiano, Peter L. Bartlett, and Michael I. Jordan. Accelerated message passing for entropy-regularized map inference. In Proceedings of the 37th International Conference on Machine Learning (ICML-20), 2020. to appear. [ bib ]
[257]	Eric Mazumdar, Aldo Pacchiano, Yian Ma, Michael I. Jordan, and Peter L. Bartlett. On Thompson sampling with Langevin algorithms. In Proceedings of the 37th International Conference on Machine Learning (ICML-20), 2020. to appear. [ bib ]
[258]	Peter L. Bartlett, Philip M. Long, Gábor Lugosi, and Alexander Tsigler. Benign overfitting in linear regression. Proceedings of the National Academy of Sciences, 117(48):30063--30070, 2020. [ bib | DOI | arXiv | http | Abstract ]
[259]	Niladri S. Chatterji, Peter L. Bartlett, and Philip M. Long. Oracle lower bounds for stochastic gradient sampling algorithms. Technical Report arXiv:2002.00291, arxiv.org, 2020. [ bib | http ]
[260]	Dhruv Malik, Ashwin Pananjady, Kush Bhatia, Koulik Khamaru, Peter L. Bartlett, and Martin J. Wainwright. Derivative-free methods for policy optimization: Guarantees for linear quadratic systems. Journal of Machine Learning Research, 21(21):1--51, 2020. [ bib | .html ]
[261]	Niladri Chatterji, Jelena Diakonikolas, Michael Jordan, and Peter L. Bartlett. Langevin Monte Carlo without smoothness. In Proceedings of the 23rd International Conference on Artificial Intelligence and Statistics (AISTATS), 2020. To appear. [ bib ]
[262]	Niladri Chatterji, Vidya Muthukumar, and Peter L. Bartlett. OSOM: A simultaneously optimal algorithm for multi-armed and linear contextual bandits. In Proceedings of the 23rd International Conference on Artificial Intelligence and Statistics (AISTATS), 2020. To appear. [ bib ]
[263]	Aldo Pacchiano, Mohammad Ghavamzadeh, Peter L. Bartlett, and Heinrich Jiang. Stochastic bandits with linear constraints. In Proceedings of the 24rd International Conference on Artificial Intelligence and Statistics (AISTATS), 2021. To appear. [ bib ]
[264]	Raman Arora, Peter L. Bartlett, Poorya Mianjy, and Nathan Srebro. Dropout: Explicit forms and capacity control. In Proceedings of the 38th International Conference on Machine Learning (ICML-21), 2021. to appear. [ bib ]
[265]	Yi-An Ma, Niladri S. Chatterji, Xiang Cheng, Nicolas Flammarion, Peter L. Bartlett, and Michael I. Jordan. Is there an analog of Nesterov acceleration for gradient-based MCMC? Bernoulli, 27(3):1942--1992, 2021. [ bib | DOI | Abstract ]
[266]	Peter L. Bartlett, Andrea Montanari, and Alexander Rakhlin. Deep learning: a statistical viewpoint. Acta Numerica, 2021. To appear. [ bib | http ]
[267]	Wenlong Mou, Yi-An Ma, Martin J. Wainwright, Peter L. Bartlett, and Michael I. Jordan. High-order Langevin diffusion yields an accelerated MCMC algorithm. Journal of Machine Learning Research, 22(42):1--41, 2021. [ bib | .html ]
[268]	Kush Bhatia, Peter L. Bartlett, Anca Dragan, and Jacob Steinhardt. Agnostic learning with unknown utilities. In Proceedings of the 12th Innovations in Theoretical Computer Science Conference (ITCS 2021), 2021. [ bib ]

# Publication[中文]

# Information Reference

https://statistics.berkeley.edu/people/peter-bartlett
https://www.stat.berkeley.edu/~bartlett/bio.html
https://www.stat.berkeley.edu/~bartlett/publications/pubs-93.html
https://www.stat.berkeley.edu/~bartlett/talks/index.html

# Notes